* Qdrant Example App
An example application show-casing hybrid search using [[https://qdrant.tech/qdrant-vector-database/][Qdrant's vector database]].

** Requirements
- [[https://docs.docker.com/compose/][Docker Compose]]
- [[https://github.com/casey/just][just]]

** Bring the server up 
This is a distributed systems simulated locally on your computer with Docker containers.
It consists of 2 Qdrant nodes, and one FastAPI server node.

Once you've run the command, wait until the server logs indicate that the startup process is complete with the message ``Application startup complete".
(It can take some time, as on first startup it will download the embedding models over the network.)

#+begin_src sh
just up
#+end_src

** Initialize the server by uploading some points 
Now let's add some vectors to Qdrant!
Let's open up a new terminal, keeping the backend live.

We're going to use a [[https://www.kaggle.com/datasets/Cornell-University/arxiv][Kaggle dataset of arXiv papers]].
This dataset consists of raw text, and thus in order to leverage Qdrant we first need to transform the records into vectors with an [[https://qdrant.github.io/fastembed/examples/Supported_Models/][embedding model]].
We need to do this thrice, as in this example we create different vectors (sparse, dense, and late interaction) to represent different aspects of the original document, which we will combine in a [[https://qdrant.tech/articles/what-is-rag-in-ai/?q=hybrid+se][hybrid search]] to provide better results. 

We do this with a Python script; but as we want to do this for more than 1M documents, it can take several hours, depending on your machine!
Thus instead of waiting hours, by default we will download 100k pre-generated embeddings.
Run the following in the root directory:

#+begin_src sh
just download_embeddings
#+end_src

Alternatively, if you just want to generate a smaller amount of embeddings locally to get a feel for how it works, then you can skip this step, and instead modify the ~DATASET_INDEX_END~ value in [[./.env][.env]] to something much smaller, i.e. ~100~.

Run the following script to upload the embeddings to your Qdrant cluster:

#+begin_src sh
just initialize 
#+end_src

You can move onto the next step as that script begins to upload the embeddings as chunks! 

** Run the example 
Now that we have a bunch of vectors in our database, we can query it!
The following command runs a simple Python script that will send a query to the server node with an HTTP request.
The server will vectorize the query, and then search for similar vectors in Qdrant using hybrid search, filtering the results by the ~user_id~ provided in the query.

#+begin_src sh
just example 
#+end_src

You should see a JSON of 10 results sent from the server, but sourced from Qdrant's powerful hybrid search.

** Play around
Peek around in the code in the [[./server/app/][server]] to see how Qdrant can be used to provide semantic search.

Once you have the cluster running via the steps explained above, the server API will exposed locally on [[http://localhost:8000]].
See the [[./scripts/run_search/main.py][run_search]] script for an example of how you can query it.
